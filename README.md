# Visual-Question-Answering_with_Transformers

This repository contains a Google Colab notebook that implements a Visual Question Answering (VQA) model using a BERT-base transformer from Hugging Face on the DAQUAR dataset. The VQA task combines computer vision and natural language processing (NLP) to answer questions about images by leveraging the powerful language understanding capabilities of BERT.
